{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9c82980-8388-4d4d-bbea-0584d60b5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLMs \n",
    "#If we wanted to interact with every LLM, we would need to learn a different API/language to communicate.\n",
    "#this is annoying.\n",
    "#Problems: Limited Context Windows, Outdated Knowledge Base, Data Privacy, Cost. No connection with 3rd party tools, Etc.\n",
    "\n",
    "\n",
    "\n",
    "#LLM Ecosystems are a combo of LLMs + a bunch of other tools. Apps,RAG, adding memory, Agents, APIs, Storage\n",
    "\n",
    "# LangChain - Orchestration Framework\n",
    "# LangSmith - LLMOps\n",
    "# Streamlit- POC Temporary UI\n",
    "# LandServe - Next+FastAPI: Deployment\n",
    "# LandGrraph- Agents Framework - complicated?\n",
    "# CrewAI - Multi-Agents Framework - easiest multi-agent app\n",
    "\n",
    "#knowledge-based tools\n",
    "#phase 2 - action-oriented agents\n",
    "\n",
    "\n",
    "#langsmith vs langgraph - langgraph is the most powerful framework from all over the world. Update resume to use it.\n",
    "\n",
    "#get list of public github Repos using x tools\n",
    "#verify the tooling they're using and how (scrape code) (run analysis on why they would use one thing over another)\n",
    "#have llm analyze the projected cost in different scenarios\n",
    "\n",
    "#backtrace developers\n",
    "\n",
    "#make Markdown so people can tell what I've done\n",
    "                   \n",
    "                                             \n",
    "# Here is how chatGPT scraped Ashar's Identity: https://chatgpt.com/c/67e4a0ef-8d90-8008-8d3d-fafb4c1bd3a2                                                                         \n",
    "# People often include their real name, location, personal website or even Linkedin. Scrape Bio, Find their name from that.                                         \n",
    "# Combine GitHub name/location info with job titles to find likely LinkedIn profiles.\n",
    "\n",
    "# Tools: LinkedIn Sales Navigator, PhantomBuster, or custom OpenAI-based fuzzy matche\n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "#To activate virtual environment:   \n",
    "#pyenv activate toolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422387ab-e2c2-4d1b-8a70-a33d65cce2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "load_dotenv()\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc16df5b-c6fc-430c-9789-8391a2501cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 repository                                     repo_url  \\\n",
      "0       davila7/youtube-gpt       https://github.com/davila7/youtube-gpt   \n",
      "1  CognitiveCodes/NeuralGPT  https://github.com/CognitiveCodes/NeuralGPT   \n",
      "2      fredsiika/huxley-pdf      https://github.com/fredsiika/huxley-pdf   \n",
      "3     eugeneyan/discord-llm     https://github.com/eugeneyan/discord-llm   \n",
      "4     eugeneyan/discord-llm     https://github.com/eugeneyan/discord-llm   \n",
      "\n",
      "                                            file_url contributor_login  \\\n",
      "0  https://github.com/davila7/youtube-gpt/blob/e8...           davila7   \n",
      "1  https://github.com/CognitiveCodes/NeuralGPT/bl...    CognitiveCodes   \n",
      "2  https://github.com/fredsiika/huxley-pdf/blob/0...         fredsiika   \n",
      "3  https://github.com/eugeneyan/discord-llm/blob/...         eugeneyan   \n",
      "4  https://github.com/eugeneyan/discord-llm/blob/...   dependabot[bot]   \n",
      "\n",
      "           name                 email  \\\n",
      "0  Daniel Avila  dan.avila7@gmail.com   \n",
      "1          None                  None   \n",
      "2    Fred Siika   fredsiika@gmail.com   \n",
      "3    Eugene Yan                  None   \n",
      "4          None                  None   \n",
      "\n",
      "                                                 bio  company  \\\n",
      "0   CodeGPT |\\r\\nBoxMagic |\\r\\nAWS Community Builder  CodeGPT   \n",
      "1                                               None     None   \n",
      "2  Pharma/Biotech Consultant | Former Oncology Re...    Capco   \n",
      "3  I build ML, RecSys, & LLM systems @Amzn, and w...   Amazon   \n",
      "4                                               None     None   \n",
      "\n",
      "                 location                                    blog  followers  \\\n",
      "0  Grand Rapids, Michigan                  https://danielavila.me        403   \n",
      "1                    None                                                  9   \n",
      "2              Dallas, TX  https://www.linkedin.com/in/fredsiika/         78   \n",
      "3                 Seattle                           eugeneyan.com       4379   \n",
      "4                    None                                                  0   \n",
      "\n",
      "   following  public_repos                            html_url  \n",
      "0         17           138          https://github.com/davila7  \n",
      "1          0             4   https://github.com/CognitiveCodes  \n",
      "2        153           154        https://github.com/fredsiika  \n",
      "3         86            78        https://github.com/eugeneyan  \n",
      "4          0             0  https://github.com/apps/dependabot  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from urllib.parse import quote\n",
    "\n",
    "load_dotenv()\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/vnd.github+json\",\n",
    "    \"Authorization\": f\"{GITHUB_TOKEN}\"\n",
    "}\n",
    "\n",
    "#Select what code or tools you want to view\n",
    "\n",
    "Tools = \"pinecone\"\n",
    "query = f\"{Tools} in:file language:python\"\n",
    "url = f\"https://api.github.com/search/code?q={quote(query)}&per_page=5&page=1\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()\n",
    "\n",
    "results = []\n",
    "\n",
    "def get_contributors_detailed(contributors_url):\n",
    "    contributor_data = []\n",
    "    response = requests.get(contributors_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        contributors = response.json()\n",
    "        for contributor in contributors:\n",
    "            user_url = contributor.get(\"url\")\n",
    "            if user_url:\n",
    "                user_response = requests.get(user_url, headers=headers)\n",
    "                if user_response.status_code == 200:\n",
    "                    user_data = user_response.json()\n",
    "                    contributor_data.append(user_data)\n",
    "    return contributor_data\n",
    "\n",
    "# Loop through each code search result\n",
    "for item in data.get(\"items\", []):\n",
    "    repo = item[\"repository\"]\n",
    "    repo_name = repo[\"full_name\"]\n",
    "    repo_url = repo[\"html_url\"]\n",
    "    file_url = item[\"html_url\"]\n",
    "    contributors_url = repo[\"contributors_url\"]\n",
    "\n",
    "    # Get full contributor profile info\n",
    "    contributors = get_contributors_detailed(contributors_url)\n",
    "\n",
    "    for contributor in contributors:\n",
    "        results.append({\n",
    "            \"repository\": repo_name,\n",
    "            \"repo_url\": repo_url,\n",
    "            \"file_url\": file_url,\n",
    "            \"contributor_login\": contributor.get(\"login\"),\n",
    "            \"name\": contributor.get(\"name\"),\n",
    "            \"email\": contributor.get(\"email\"),\n",
    "            \"bio\": contributor.get(\"bio\"),\n",
    "            \"company\": contributor.get(\"company\"),\n",
    "            \"location\": contributor.get(\"location\"),\n",
    "            \"blog\": contributor.get(\"blog\"),\n",
    "            \"followers\": contributor.get(\"followers\"),\n",
    "            \"following\": contributor.get(\"following\"),\n",
    "            \"public_repos\": contributor.get(\"public_repos\"),\n",
    "            \"html_url\": contributor.get(\"html_url\"),\n",
    "        })\n",
    "\n",
    "        \n",
    "     \n",
    "        \n",
    "        \n",
    "# Build DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "df.to_csv(\"new_contributor_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d115cfb-2e41-4ac4-af95-a0fd3f2c4a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f2a9e-325c-4329-8aae-0a2d9adec6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
